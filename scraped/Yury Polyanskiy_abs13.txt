
It is shown that under suitable regularity conditions, differential entropy
is a Lipschitz functional on the space of distributions on $n$-dimensional
Euclidean space with respect to the quadratic Wasserstein distance. Under
similar conditions, (discrete) Shannon entropy is shown to be Lipschitz
continuous in distributions over the product space with respect to Ornstein's
$\bar d$-distance (Wasserstein distance corresponding to the Hamming distance).
These results together with Talagrand's and Marton's transportation-information
inequalities allow one to replace the unknown multi-user interference with its
i.i.d. approximations. As an application, a new outer bound for the two-user
Gaussian interference channel is proved, which, in particular, settles the
"missing corner point" problem of Costa (1985).
