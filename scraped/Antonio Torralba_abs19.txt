
The complex multi-stage architecture of cortical visual pathways provides the
neural basis for efficient visual object recognition in humans. However, the
stage-wise computations therein remain poorly understood. Here, we compared
temporal (magnetoencephalography) and spatial (functional MRI) visual brain
representations with representations in an artificial deep neural network (DNN)
tuned to the statistics of real-world visual recognition. We showed that the
DNN captured the stages of human visual processing in both time and space from
early visual areas towards the dorsal and ventral streams. Further
investigation of crucial DNN parameters revealed that while model architecture
was important, training on real-world categorization was necessary to enforce
spatio-temporal hierarchical relationships with the brain. Together our results
provide an algorithmically informed view on the spatio-temporal dynamics of
visual object recognition in the human visual brain.
